{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-13T20:54:39.669802Z","iopub.execute_input":"2023-11-13T20:54:39.670773Z","iopub.status.idle":"2023-11-13T20:54:40.050963Z","shell.execute_reply.started":"2023-11-13T20:54:39.670724Z","shell.execute_reply":"2023-11-13T20:54:40.049906Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\n/kaggle/input/contradictory-my-dear-watson/train.csv\n/kaggle/input/contradictory-my-dear-watson/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\")","metadata":{"execution":{"iopub.status.busy":"2023-11-13T20:54:42.131116Z","iopub.execute_input":"2023-11-13T20:54:42.131545Z","iopub.status.idle":"2023-11-13T20:54:48.149535Z","shell.execute_reply.started":"2023-11-13T20:54:42.131519Z","shell.execute_reply":"2023-11-13T20:54:48.148727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, load_dataset, Value\n\ntrain_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\").loc[:, [\"premise\", \"hypothesis\", \"label\"]]\ntest_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\").loc[:, [\"premise\", \"hypothesis\", \"id\"]]\n\ntrain_ds = Dataset.from_pandas(train_data)\ntest_ds = Dataset.from_pandas(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:55:10.095471Z","iopub.execute_input":"2023-11-13T21:55:10.096251Z","iopub.status.idle":"2023-11-13T21:55:10.209403Z","shell.execute_reply.started":"2023-11-13T21:55:10.096212Z","shell.execute_reply":"2023-11-13T21:55:10.208372Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if _pandas_api.is_sparse(col):\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=\"max_length\", truncation=True)\n    \n    return examples","metadata":{"execution":{"iopub.status.busy":"2023-11-13T20:54:53.182088Z","iopub.execute_input":"2023-11-13T20:54:53.182813Z","iopub.status.idle":"2023-11-13T20:54:53.187787Z","shell.execute_reply.started":"2023-11-13T20:54:53.182780Z","shell.execute_reply":"2023-11-13T20:54:53.186704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tok_train_ds = train_ds.map(tokenize_function, batched=True).remove_columns([\"premise\", \"hypothesis\"])\ntok_test_ds = test_ds.map(tokenize_function, batched=True).remove_columns([\"premise\", \"hypothesis\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-13T20:54:55.366883Z","iopub.execute_input":"2023-11-13T20:54:55.367274Z","iopub.status.idle":"2023-11-13T20:55:02.303890Z","shell.execute_reply.started":"2023-11-13T20:54:55.367249Z","shell.execute_reply":"2023-11-13T20:55:02.302939Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69a9df061da54e86a2730d01d5f8fba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49193de29fe94e4688cd9bed51671216"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:38:41.848120Z","iopub.execute_input":"2023-11-13T22:38:41.848513Z","iopub.status.idle":"2023-11-13T22:38:53.919411Z","shell.execute_reply.started":"2023-11-13T22:38:41.848481Z","shell.execute_reply":"2023-11-13T22:38:53.918150Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.17.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.14.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nfrom peft import IA3Model, IA3Config\n\n\ntraining_args = TrainingArguments(\n    num_train_epochs=3,\n    learning_rate=2e-05,\n    gradient_accumulation_steps=2, \n    per_device_train_batch_size=8,\n    warmup_ratio=0.06,               \n    weight_decay=0.01,               \n    fp16=False,\n    output_dir=\"results\",\n    remove_unused_columns=False\n)\n\npeft_config = IA3Config(\n    task_type=\"NLI\",\n    target_modules=[\"key_proj\", \"value_proj\", \"down_proj\"],\n    feedforward_modules=[\"down_proj\"]\n)\n\nia3model = IA3Model(model=model, config=peft_config, adapter_name=\"default\")\n    \ntrainer = Trainer(\n    model=ia3model,\n    args=training_args,\n    train_dataset=tok_train_ds)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T20:58:37.337128Z","iopub.execute_input":"2023-11-13T20:58:37.337501Z","iopub.status.idle":"2023-11-13T21:38:29.768408Z","shell.execute_reply.started":"2023-11-13T20:58:37.337468Z","shell.execute_reply":"2023-11-13T21:38:29.767452Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1137' max='1137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1137/1137 39:49, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.423900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.411200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1137, training_loss=0.4212650913047287, metrics={'train_runtime': 2391.8242, 'train_samples_per_second': 15.202, 'train_steps_per_second': 0.475, 'total_flos': 9569034252656640.0, 'train_loss': 0.4212650913047287, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"./first_model\")","metadata":{"execution":{"iopub.status.busy":"2023-11-13T21:40:54.478316Z","iopub.execute_input":"2023-11-13T21:40:54.479111Z","iopub.status.idle":"2023-11-13T21:40:57.115518Z","shell.execute_reply.started":"2023-11-13T21:40:54.479076Z","shell.execute_reply":"2023-11-13T21:40:57.114348Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\nfrom transformers.pipelines.pt_utils import KeyDataset\n\npipe = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=\"cuda\")\nids = test_ds[\"id\"]\n\nlabel2num = {\n    \"entailment\": 0,\n    \"neutral\": 1,\n    \"contradiction\": 2\n}\n\nwith open(\"submission.csv\", \"w\") as f:\n    f.write(\"id,prediction\\n\")\n    \nwith open(\"submission.csv\", \"a\") as f:    \n    for id_, out in zip(ids, pipe(KeyDataset(test_ds, \"premise\"))):\n        f.write(id_ + ',' + str(label2num[out[\"label\"]]) + \"\\n\")\n   ","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:29:16.402523Z","iopub.execute_input":"2023-11-13T22:29:16.403404Z","iopub.status.idle":"2023-11-13T22:32:32.149101Z","shell.execute_reply.started":"2023-11-13T22:29:16.403355Z","shell.execute_reply":"2023-11-13T22:32:32.147962Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}