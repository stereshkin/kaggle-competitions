{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T20:54:39.670773Z",
     "iopub.status.busy": "2023-11-13T20:54:39.669802Z",
     "iopub.status.idle": "2023-11-13T20:54:40.050963Z",
     "shell.execute_reply": "2023-11-13T20:54:40.049906Z",
     "shell.execute_reply.started": "2023-11-13T20:54:39.670724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\n",
      "/kaggle/input/contradictory-my-dear-watson/train.csv\n",
      "/kaggle/input/contradictory-my-dear-watson/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T20:54:42.131545Z",
     "iopub.status.busy": "2023-11-13T20:54:42.131116Z",
     "iopub.status.idle": "2023-11-13T20:54:48.149535Z",
     "shell.execute_reply": "2023-11-13T20:54:48.148727Z",
     "shell.execute_reply.started": "2023-11-13T20:54:42.131519Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T21:55:10.096251Z",
     "iopub.status.busy": "2023-11-13T21:55:10.095471Z",
     "iopub.status.idle": "2023-11-13T21:55:10.209403Z",
     "shell.execute_reply": "2023-11-13T21:55:10.208372Z",
     "shell.execute_reply.started": "2023-11-13T21:55:10.096212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, Value\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\").loc[:, [\"premise\", \"hypothesis\", \"label\"]]\n",
    "test_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\").loc[:, [\"premise\", \"hypothesis\", \"id\"]]\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_data)\n",
    "test_ds = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T20:54:53.182813Z",
     "iopub.status.busy": "2023-11-13T20:54:53.182088Z",
     "iopub.status.idle": "2023-11-13T20:54:53.187787Z",
     "shell.execute_reply": "2023-11-13T20:54:53.186704Z",
     "shell.execute_reply.started": "2023-11-13T20:54:53.182780Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T20:54:55.367274Z",
     "iopub.status.busy": "2023-11-13T20:54:55.366883Z",
     "iopub.status.idle": "2023-11-13T20:55:02.303890Z",
     "shell.execute_reply": "2023-11-13T20:55:02.302939Z",
     "shell.execute_reply.started": "2023-11-13T20:54:55.367249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a9df061da54e86a2730d01d5f8fba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49193de29fe94e4688cd9bed51671216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_train_ds = train_ds.map(tokenize_function, batched=True).remove_columns([\"premise\", \"hypothesis\"])\n",
    "tok_test_ds = test_ds.map(tokenize_function, batched=True).remove_columns([\"premise\", \"hypothesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T22:38:41.848513Z",
     "iopub.status.busy": "2023-11-13T22:38:41.848120Z",
     "iopub.status.idle": "2023-11-13T22:38:53.919411Z",
     "shell.execute_reply": "2023-11-13T22:38:53.918150Z",
     "shell.execute_reply.started": "2023-11-13T22:38:41.848481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.17.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.14.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T20:58:37.337501Z",
     "iopub.status.busy": "2023-11-13T20:58:37.337128Z",
     "iopub.status.idle": "2023-11-13T21:38:29.768408Z",
     "shell.execute_reply": "2023-11-13T21:38:29.767452Z",
     "shell.execute_reply.started": "2023-11-13T20:58:37.337468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1137' max='1137' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1137/1137 39:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.411200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1137, training_loss=0.4212650913047287, metrics={'train_runtime': 2391.8242, 'train_samples_per_second': 15.202, 'train_steps_per_second': 0.475, 'total_flos': 9569034252656640.0, 'train_loss': 0.4212650913047287, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import IA3Model, IA3Config, TaskType\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-05,\n",
    "    gradient_accumulation_steps=2, \n",
    "    per_device_train_batch_size=8,\n",
    "    warmup_ratio=0.06,               \n",
    "    weight_decay=0.01,               \n",
    "    fp16=False,\n",
    "    output_dir=\"results\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "peft_config = IA3Config(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"key_proj\", \"value_proj\", \"down_proj\"],\n",
    "    feedforward_modules=[\"down_proj\"]\n",
    ")\n",
    "\n",
    "ia3model = IA3Model(model=model, config=peft_config, adapter_name=\"default\")\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=ia3model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_train_ds)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T21:40:54.479111Z",
     "iopub.status.busy": "2023-11-13T21:40:54.478316Z",
     "iopub.status.idle": "2023-11-13T21:40:57.115518Z",
     "shell.execute_reply": "2023-11-13T21:40:57.114348Z",
     "shell.execute_reply.started": "2023-11-13T21:40:54.479076Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./first_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T22:29:16.403404Z",
     "iopub.status.busy": "2023-11-13T22:29:16.402523Z",
     "iopub.status.idle": "2023-11-13T22:32:32.149101Z",
     "shell.execute_reply": "2023-11-13T22:32:32.147962Z",
     "shell.execute_reply.started": "2023-11-13T22:29:16.403355Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "pipe = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "ids = test_ds[\"id\"]\n",
    "\n",
    "label2num = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}\n",
    "\n",
    "with open(\"submission.csv\", \"w\") as f:\n",
    "    f.write(\"id,prediction\\n\")\n",
    "    \n",
    "with open(\"submission.csv\", \"a\") as f:    \n",
    "    for id_, out in zip(ids, pipe(KeyDataset(test_ds, \"premise\"))):\n",
    "        f.write(id_ + ',' + str(label2num[out[\"label\"]]) + \"\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1408234,
     "sourceId": 21733,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
